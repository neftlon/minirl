{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cliff_jax import Cliff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Cliff.default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(16, dtype=int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "internal_state = env.reset()\n",
    "env.observe(internal_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(InternalState(state=Array(16, dtype=int32), step=Array(1, dtype=int32, weak_type=True)),\n",
       " Array(-1, dtype=int32, weak_type=True),\n",
       " Array(False, dtype=bool))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(internal_state, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "import jax, jax.numpy as jnp, jax.random as jr\n",
    "key = jr.key(0)\n",
    "\n",
    "class Embedding(typing.NamedTuple):\n",
    "  num_emb: int\n",
    "  emb_dim: int\n",
    "\n",
    "  def __call__(self, params, _key, x):\n",
    "    return params[x]\n",
    "  \n",
    "  def logp(self, params, x, y):\n",
    "    logits = self(params, ..., x)\n",
    "    return jax.nn.log_softmax(logits)[y]\n",
    "\n",
    "  def init(self, key):\n",
    "    return jr.normal(key, (self.num_emb, self.emb_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpsGreedy(typing.NamedTuple):\n",
    "  model: typing.Any\n",
    "  num_actions: int\n",
    "  eps: float = .1\n",
    "\n",
    "  def __call__(self, params, key, *args):\n",
    "    key, eps_key = jr.split(key)\n",
    "    # use cond to run the model only when it's necessary\n",
    "    return jax.lax.cond(\n",
    "      jr.uniform(eps_key) >= self.eps,\n",
    "      # take model's prediction (greedy)\n",
    "      lambda: self.model(params, key, *args).argmax(axis=-1),\n",
    "      # select a random action\n",
    "      lambda: jr.choice(key, self.num_actions),\n",
    "    )\n",
    "  \n",
    "  def logp(self, params, x, y):\n",
    "    return jnp.log(self.eps / self.num_actions + (1 - self.eps) * jnp.exp(self.model.logp(params, x, y)))\n",
    "\n",
    "  def init(self, key):\n",
    "    return self.model.init(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_tab = Embedding(24, 4)\n",
    "eps_greedy = EpsGreedy(action_tab, 4)\n",
    "key, model_key = jr.split(key)\n",
    "params = eps_greedy.init(model_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "for _ in range(3):\n",
    "  obs = env.observe(state) # extract the observation from the state\n",
    "  key, action_key = jr.split(key)\n",
    "  action = eps_greedy(params, action_key, obs)\n",
    "  state, reward, done = env.step(state, action)\n",
    "  if done:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Buf(typing.NamedTuple):\n",
    "  max_num_eps: int\n",
    "  max_episode_len: int\n",
    "\n",
    "  class State(typing.NamedTuple):\n",
    "    offset: int # current location in the buffer\n",
    "    num_eps: int # number of episodes that is contained in this buffer\n",
    "    ep_ends: jax.Array # end markers for episodes in the buffer (exclusive)\n",
    "    observations: typing.Any\n",
    "    actions: typing.Any\n",
    "    rewards: typing.Any\n",
    "\n",
    "    @property\n",
    "    def ep_starts(self) -> jax.Array:\n",
    "      starts = jnp.zeros_like(self.ep_ends)\n",
    "      return starts.at[1:].set(self.ep_ends[:-1])\n",
    "    \n",
    "    @property\n",
    "    def buf_size(self) -> int:\n",
    "      return len(self.observations)\n",
    "\n",
    "    def reset(self) -> \"Buf.State\":\n",
    "      return Buf.State(\n",
    "        offset=0,\n",
    "        num_eps=0,\n",
    "        ep_ends=self.ep_ends,\n",
    "        observations=self.observations,\n",
    "        actions=self.actions,\n",
    "        rewards=self.rewards,\n",
    "      )\n",
    "  \n",
    "  def can_append_episode(self, state: \"State\") -> bool:\n",
    "    free = state.buf_size - state.offset\n",
    "    return (state.num_eps < self.max_num_eps) and (free >= self.max_episode_len)\n",
    "\n",
    "  def append(self, state: \"State\", obs, action, reward) -> \"State\":\n",
    "    newoffset = state.offset + 1\n",
    "    in_bounds = newoffset < len(state.observations)\n",
    "    return Buf.State(\n",
    "      offset=jnp.where(in_bounds, newoffset, state.offset),\n",
    "      num_eps=state.num_eps,\n",
    "      ep_ends=state.ep_ends,\n",
    "      observations=jnp.where(in_bounds, state.observations.at[state.offset].set(obs), state.observations),\n",
    "      actions=jnp.where(in_bounds, state.actions.at[state.offset].set(action), state.actions),\n",
    "      rewards=jnp.where(in_bounds, state.rewards.at[state.offset].set(reward), state.rewards),\n",
    "    )\n",
    "\n",
    "  def end_episode(self, state: \"State\") -> \"State\":\n",
    "    # Safety: calling can_append_episode before appending/ending an episode ensures that there is enough space\n",
    "    return Buf.State(\n",
    "      offset=state.offset,\n",
    "      num_eps=state.num_eps + 1,\n",
    "      ep_ends=state.ep_ends.at[state.num_eps].set(state.offset),\n",
    "      observations=state.observations,\n",
    "      actions=state.actions,\n",
    "      rewards=state.rewards,\n",
    "    )\n",
    "  \n",
    "  def empty(self, buf_size: typing.Optional[int] = None) -> \"State\":\n",
    "    if buf_size is None:\n",
    "      buf_size = self.max_num_eps * self.max_episode_len\n",
    "    return Buf.State(\n",
    "      offset=0,\n",
    "      num_eps=0,\n",
    "      ep_ends=jnp.zeros(self.max_num_eps, dtype=int),\n",
    "      observations=jnp.zeros(buf_size, dtype=int),\n",
    "      actions=jnp.zeros(buf_size, dtype=int),\n",
    "      rewards=jnp.zeros(buf_size),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "buf = Buf(20, env.max_steps)\n",
    "buf_state = buf.empty(buf_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State(offset=Array(11, dtype=int32, weak_type=True), num_eps=9, ep_ends=Array([ 2,  3,  4,  5,  7,  8,  9, 10, 11, 11, 11,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0], dtype=int32), observations=Array([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0], dtype=int32), actions=Array([3, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), rewards=Array([ -1., -50., -50., -50., -50.,  -1., -50., -50., -50., -50., -50.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.], dtype=float32))"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buf_state = buf_state.reset()\n",
    "while buf.can_append_episode(buf_state):\n",
    "  state = env.reset()\n",
    "  while True: # NB: the environment is responsible for terminating after a couple of steps\n",
    "    obs = env.observe(state) # extract the observation from the state\n",
    "    key, action_key = jr.split(key)\n",
    "    action = eps_greedy(params, action_key, obs)\n",
    "    state, reward, done = env.step(state, action)\n",
    "    buf_state = buf.append(buf_state, obs, action, reward)\n",
    "    if done:\n",
    "      break\n",
    "  buf_state = buf.end_episode(buf_state)\n",
    "buf_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array(2, dtype=int32),\n",
       " Array([ -1., -50., -50., -50., -50.,  -1., -50., -50., -50., -50.],      dtype=float32))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buf_state.ep_ends[0], buf_state.rewards[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([-51., -50., -50., -50., -51., -50., -50., -50., -50.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],      dtype=float32)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute cumulative reward per episode\n",
    "eprew = jnp.zeros(buf.max_num_eps)\n",
    "epidx, offset = 0, 0\n",
    "while epidx < buf_state.num_eps:\n",
    "  # accumulate rewards\n",
    "  reward = buf_state.rewards[offset]\n",
    "  eprew = eprew.at[epidx].set(eprew[epidx] + reward) # TODO: introduce a discount factor\n",
    "\n",
    "  # update loop variables\n",
    "  offset += 1\n",
    "  epidx = jnp.where(offset >= buf_state.ep_ends[epidx], epidx + 1, epidx)\n",
    "eprew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accumulate_rewards(buf_state, ep_idx, offset, ep_rew):\n",
    "  reward = buf_state.rewards[offset]\n",
    "  return ep_rew.at[ep_idx].set(ep_rew[ep_idx] + reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([-51., -50., -50., -50., -51., -50., -50., -50., -50.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],      dtype=float32)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reduce_episodes(fn, carry_init, buf_state: Buf.State):\n",
    "  class LoopState(typing.NamedTuple):\n",
    "    carry: typing.Any\n",
    "    epidx: jax.Array # int\n",
    "\n",
    "  def body(offset: int, state: LoopState):\n",
    "    not_done = offset < buf_state.offset # buf's current level is not reached yet\n",
    "    next_offset_overflow = (offset + 1) >= buf_state.ep_ends[state.epidx] # increase eps idx preventive\n",
    "    return LoopState(\n",
    "      carry=jnp.where(not_done, fn(buf_state, state.epidx, offset, state.carry), state.carry),\n",
    "      epidx=jnp.where(not_done & next_offset_overflow, state.epidx + 1, state.epidx)\n",
    "    )\n",
    "  \n",
    "  state = LoopState(carry_init, jnp.asarray(0))\n",
    "  state = jax.lax.fori_loop(0, buf_state.buf_size, body, state)\n",
    "  return state.carry\n",
    "weights = reduce_episodes(accumulate_rewards, jnp.zeros(buf.max_num_eps), buf_state)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accumulate_logps(buf_state: Buf.State, ep_idx, offset, logps):\n",
    "  obs, act = buf_state.observations[offset], buf_state.actions[offset]\n",
    "  logp = eps_greedy.logp(params, obs, act) # compute \\pi(s_t\\vert a_t)\n",
    "  return logps.at[ep_idx].set(logps[ep_idx] + logp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([-2.094716  , -0.87386847, -0.87386847, -0.87386847, -2.5958457 ,\n",
       "       -0.87386847, -0.87386847, -0.87386847, -0.87386847,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ],      dtype=float32)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logps = reduce_episodes(accumulate_logps, jnp.zeros(buf.max_num_eps), buf_state)\n",
    "logps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_reward(params, buf_state: Buf.State) -> jax.Array:\n",
    "  # compute sum of rewards for each episode\n",
    "  def accumulate_rewards(buf_state, ep_idx, offset, ep_rew):\n",
    "    reward = buf_state.rewards[offset]\n",
    "    return ep_rew.at[ep_idx].set(ep_rew[ep_idx] + reward)\n",
    "\n",
    "  # compute sum of logps for each episode\n",
    "  def accumulate_logps(buf_state: Buf.State, ep_idx, offset, logps):\n",
    "    obs, act = buf_state.observations[offset], buf_state.actions[offset]\n",
    "    logp = eps_greedy.logp(params, obs, act) # compute \\pi(s_t\\vert a_t)\n",
    "    return logps.at[ep_idx].set(logps[ep_idx] + logp)\n",
    "    \n",
    "  weights = reduce_episodes(accumulate_rewards, jnp.zeros(buf.max_num_eps), buf_state)\n",
    "  logps = reduce_episodes(accumulate_logps, jnp.zeros(buf.max_num_eps), buf_state)\n",
    "  # weight logps and compute average to approximate E[J(\\pi)] over all episodes\n",
    "  return jnp.sum(weights * logps) / buf_state.num_eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[  0.      ,   0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ,   0.      ],\n",
       "       [  5.343898,   4.90797 , -22.246414,  11.994543],\n",
       "       [  0.      ,   0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ,   0.      ],\n",
       "       [  0.      ,   0.      ,   0.      ,   0.      ]], dtype=float32)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.grad(expected_reward)(params, buf_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "expjax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
